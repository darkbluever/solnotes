title: "A/B Testing中的统计学简述"
date: 2016-10-08 16:16:53
categories:
- 数学
tags:
- 统计学
- 数学
- A/B testing
mathjax: true
---

## 引子
最近做了一个 A/B 测试相关的项目，填补了这部分知识的空白。以前只知道 A/B 测试的大概机制，对原理并没有什么了解，通过这个项目，对 A/B 测试的统计学原理有了一点了解，遂决定记录成文，顺便更新下大半年没动过的博客……
<!-- more -->


## A/B testing
A/B 测试大家应该都有所了解，所以就简单引用一下定义：

> In marketing and business intelligence, A/B testing is a term for a randomized experiment with two variants, A and B, which are the control and variation in the controlled experiment.[1]
> A/B testing is a form of statistical hypothesis testing with two variants leading to the technical term, two-sample hypothesis testing, used in the field of statistics.
> -- [wikipedia](https://en.wikipedia.org/wiki/A/B_testing)

即，A/B 测试是一种两样本的随机对照试验，在统计学上是一种两样本的假设检验。在计算机方面，A/B 测试通常是为了通过评估对照组和实验组之间的差异，决定产品迭代的方向。A/B 测试的概念也被扩展到多样本的实验方式上。

我之前对 A/B 测试的理解仅限于大概流程，实验设计->流量划分->实验进行->数据采集->数据分析->结论产出，但是一直没想过数据分析是如何进行的，这次主要填补的就是这部分的内容。


## 总体与样本
总体即研究对象的某项数量指标的全体。总体中个每个元素称为个体。在A/B测试中，我们产品的所有用户的某项指标构成总体，例如用户的付款转化率等。

实际应用中，通常总体的量级可能会非常大，不适于直接在总体上做实验并分析数据；或者不希望过多的用户参与到 A/B 测试中，避免对大部分用户造成打扰，所以一般做 A/B 测试都是使用小流量进行的，即流量划分这一步会决定哪部分流量进行实验，根据对这一部分流量的实验数据进行分析，将结论推广到全部流量。流量划分即通过抽样来从总体中划定实验范围的过程。

抽样，是指按照一定规则从总体中抽取若干个体进行观察试验，以推断总体的分布及特征等信息的方式。最常用的抽样方法是随机抽样，即从总体中随机抽取n个个体作为样本，使得每一个个体都有相同的概率被抽中。常用于个体间差异较小，且互相独立的情况。此外使用较多的还有分层抽样，即将个体按照某种特征或规则划分为不同的层，然后从不同的层中独立、随机地抽取样本，从而保证样本的结构和总体的结构相近。

抽样最重要的一点就是要尽量保证样本具有代表性，避免样本误差对实验结论的影响，否则根据有偏差的样本得出的数据和结论可能会带来误导。


## 统计量及其分布
在选择完抽样方法后，还需要选择适当的统计指标来评估对照组和实验组的表现。通常，我们选择的都是一维连续随机变量，例如pv、uv、点击率等，随机变量的分布函数描述了随机变量的概率分布的情况。我们实际常用的分布主要是正态分布和t分布。

### 正态分布
正态分布是一种应用非常广泛的概率分布，正态分布的密度曲线是一条关于 $x = \mu$ 对称的钟形曲线，方差 $\sigma ^{2}$ 决定了曲线中峰的陡峭程度。其中，$\mu$ 是正态分布的数学期望，$\sigma ^{2}$ 是正态分布的方差，正态分布记为 $X \sim N(\mu,\sigma ^ {2})$。$\mu = 0$ 且 $\sigma ^{2} = 1$ 时的正态分布称为标准正态分布，记为 $X \sim N(0,1)$。

![](https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Normal_Distribution_PDF.svg/350px-Normal_Distribution_PDF.svg.png "normal distribution")

根据中心极限定理，一个变量如果是由大量微小的、独立的随机因素叠加的结果，那么当样本量足够大的时候，这个变量近似服从正态分布。

![](https://upload.wikimedia.org/wikipedia/commons/0/06/De_moivre-laplace.gif "central limit theorem")

### t分布
通常情况下，我们无法知道正态分布的总体的方差，只能用样本方差近似的代替总体方差进行计算，当样本量比较大的时候，我们可以取到比较好的近似值，但是当样本量不足的时候，误差较大，所以需要应用t分布来计算。

t分布曲线和标准正态分布曲线非常接近，t分布的最大值比标准正态分布略小，尾部的概率比标准正态分布大一些。样本量越大，t分布的越接近标准正态分布，当样本量充分大的时候，t分布可以近似看作是标准正态分布。

![](https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/TStudent.png/325px-TStudent.png "student distribution")


## 参数估计
根据采集到的样本数据，可以计算样本的均值、方差、标准差等分布特征。但是根据对样本数据的计算得到的特征值存在一定的偏差，并不能准确反应总体分布特征，因此需要根据样本特征值对总体进行估计。

参数估计的形式有两种：

- 点估计：根据样本估计参数的近似值
- 区间估计：根据样本构造一个参数的取值范围，使得待估参数落在这个范围中的可信程度较高

### 置信区间
置信区间是区间估计的一种，是指在样本量不变的前提下，我们重复抽样，用同样的方法构造置信区间，有95%的置信区间会包含真实值，所以当我们只构造一次置信区间的时候，我们也认为这个区间是可信的，是包含了总体参数真实值的。这个概率也被称为置信度。置信度越高，结果的可靠性也就越高，但是置信度的提高往往伴随着区间的扩大。

![](http://zy.swust.net.cn/14/1/dzclyyb/kcxx/z2/image/5_clip_image011.jpg "confidence interval")


## 假设检验
假设检验通常用来根据样本数据推断总体的某些性质，先对总体的参数提出某种假设，然后利用样本数据判断假设是否成立。在A/B测试中，通常我们希望推断的性质是优化指标的总体期望，即实验组对应的总体的某个优化指标的均值是否优于对照组的相应总体指标。

假设检验运用了反证法，其一般流程是

- 提出原假设和备择假设，原假设的内容一般是希望被证明为错误的假设或者需要着重考虑的假设。与原假设相对的是备择假设，即希望被证明是正确的另一种可能
- 选择检验方法和检验统计量
- 在原假设下推导统计量的分布，比如正态分布或t分布等
- 选择显著性水平
- 计算拒绝域，如果统计量未落在拒绝域，则接受原假设，如果统计量落在拒绝域，则接受备择假设。

### 显著性检验
拒绝域即拒绝原假设的区域，其概率即为显著性水平。常用显著性水平如5%、1%等，即在原假设成立的条件下，样本值落在拒绝域的概率很低，是一个小概率事件，按照实际推断原理，小概率事件在一次抽样中一般是不会发生的，因为我们有理由认为样本值落在拒绝域的时候，原假设是不成立的。

不过实际推断原理只是说在一次抽样中，小概率事件可以认为是不会发生的，而不能肯定绝对不发生。因此，有一定概率在原假设成立的情况下，统计量落入拒绝域，导致我们拒绝原假设。这种情况实际上是一种错误，在假设检验中，称这种错误为第一类错误，也就是“弃真”错误，发生的概率记作 $\alpha$，即显著性水平。另一种错误是原假设不成立，但是接受了原假设，称为第二类错误，即“受伪”错误，它发生的概率记作 $\beta$。

由于抽样的随机性，我们不可能完全排除这两类错误的发生，因此只能把这两类错误控制在一定的范围之内。当样本容量 n 确定之后，犯两类错误的概率不可能同时降低，通常我们会用一个较小的显著性水平 $\alpha$ 来控制第一类错误的发生，因为原假设一般是结合问题特点提出的，需要着重考虑的假设，不应该轻易拒绝，所以第一类错误的概率要控制得较小。这种只控制犯第一类错误的概率，而不考虑犯第二类错误的概率的检验，称为显著性检验。

### 双侧检验，单侧检验
实际应用中，我们经常会区分双侧检验和单侧检验，这是根据备择假设的定义选定的，即：

- 双侧检验：如果备择假设没有特定的方向性，这样的检验称为双侧检验，对于正态分布而言，拒绝域分布在曲线的两端
- 单侧检验：如果备择假设具有特定的方向性，这样的检验称为单侧检验，对于正态分布而言，拒绝域在曲线的一侧
![](http://course.cau-edu.net.cn/course/Z0193/ch06/se01/content/htmlimages/index_3.gif "hypothesis testing")

### 检验方法
上述流程中，有一步选择检验方法，在A/B测试中，我们通常计算的统计量都服从正态分布或t分布，这里以此为例进行展开。

比较常用的检验方法包括Z检验和t检验，选择取决于总体方差和样本量。

- 总体方差已知：Z检验
- 总体方差未知，样本量大于30：t检验，或者Z检验，用样本方差近似代替总体方差
- 总体方差未知，样本量小于30：t检验


#### Z检验
Z检验适用于大样本的两平均数之间差异显著性检验的方法，它是通过计算两个平均数之间差的Z分数来与规定的理论Z值相比较，从而判定两平均数的差异是否显著的一种差异显著性检验方法。

Z统计量的计算公式为：
$$Z = \frac{X - \mu}{\sigma}$$

Z统计量用来度量观测到的统计量和假设总体参数之间的差值，以标准差为单位，可以看做使用总体的期望和标准差对随机变量 X 进行标准化的结果。当随机变量 X 无法确定时，则为样本的平均数，Z 统计量的计算公式修改为：
$$Z = \frac{\bar X - \mu}{\frac{\sigma}{\sqrt n}}$$

其中，$\bar X$ 是样本均值，$\mu$ 是总体期望，$\sigma$ 是总体标准差，n 是样本数量，$\frac{\sigma}{\sqrt n}$ 是样本标准误差。样本的标准误差用来估计来自于同一总体的多个样本所得到的样本均值之间的差异性。使用均值的标准误差可以确定样本均值的评估精确度。标准误差的值越小，表示对总体的评估越精确。


#### t检验
t检验是用t分布理论来推断两个平均数差异的显著性检验。常用于根据小样本来估计呈正态分布且方差未知的总体的均值，如果方差已知，应该用正态分布来估计总体均值。t检验是对Z检验的改进，因为Z检验的前提是总体的标准差已知，虽然在样本数量大(通常是30)的时候，可以用Z检验求得近似值，但样本量小的时候，误差较大，因此要改用t检验以求准确。

t统计量的计算公式为：
$$t = \frac{\bar X - \mu}{\frac{S}{\sqrt n}}$$

其中，$\bar X$ 是样本均值，$\mu$ 是总体期望，n 是样本数量，S 是样本标准差，计算公式为 $S=\sqrt {\frac{\sum_{i=0}^n (x_i - \bar x)^2}{n-1}}$，$\frac{S}{\sqrt n}$ 是样本标准误差。

这个时候，我们说统计量满足自由度为(n-1)的t分布。其中自由度是指当以样本的统计量来估计总体的参数时，样本中能独立或能自由变化的数据的个数。在使用样本均值近似替代总体期望计算样本方差的过程中，因为样本均值已经确定了，所以样本方差的自由度是 n-1 。

t统计量以标准误差的单位度量观测的样本统计量与其假设的总体参数之差，t检验将此观测的t统计量与自由度为 n-1 的 t 分布中的临界值进行比较，以确定估计和假设的总体参数值之差是否在统计意义上显著。

常用t检验的情况：

- 单样本检验：检验一个正态分布的总体的均值是否满足原假设
- 双样本检验：检验两个正态分布的总体均值之差是否满足原假设
- 配对t检验：检验一个正态分布的两组配对样本的总体均值之差或一组样本的前后两次测量的总体均值之差是否满足原假设

我们实际应用的时候，对比实验组和对照组的统计量差异的时候，符合配对t检验的情况，此时，t统计量的公式为
$$t = \frac{\bar d - \mu}{\frac{S_d}{\sqrt n}}$$

其中，n是样本数量，n-1是自由度，$d_i = x_{1i} - x_{2i}$ 是样本元素，$\bar d = \frac{\sum_{i=0}^n d_i}{n}$ 是样本均值，$S_d = \sqrt{\frac{\sum_{i=0}^n (d_i - \bar d)^2}{n-1}}$ 是样本标准差。


### p-value
在假设检验的过程中，我们经常听到 p 值这个名词，它的含义是：在原假设成立的条件下，我们观察到计算所得样本数据特征的概率，通常将 p 值和显著性水平进行比较以判断是否拒绝原假设。如果 p 值小于显著性水平，说明我们在原假设的条件下几乎不会得到这样的数据，所以我们应该拒绝原假设。

![](http://7xiium.com1.z0.glb.clouddn.com/p-value.png)


## 示例
下面我们通过一个例子梳理一下。假设我们设计了一个实验，通过随机抽样选出了样本，经过一段时间的实验，收集到了一批样本的数据。为了比较实验组和对照组的差异，我们首先提出原假设和备择假设：

- 原假设 H0：实验组与对照组的统计指标没有差异，即 $\mu_d = 0$
- 备择假设 H1：实验组与对照组的统计指标有明显差异，即 $\mu_d \neq 0$

然后我们定义实验组和对照组之间统计量的差异为 $d_i= x_{1i} - x_{2i}$, 现在假设我们的统计量服从正态分布，这样 $d_i$ 也服从正态分布，分布的方差未知。接下来我们根据样本数量选择使用Z检验或者t检验，假设我们样本量不足，使用t检验。这时我们可以先计算得到样本数据的均值 $\bar d$，然后根据样本均值计算样本方差，公式为：
$$S^2 = \frac{\sum_{i=0}^n (d_i - \bar d)^2}{n-1}$$

根据样本均值和标准差可以计算t统计量，计算公式为：
$$t = \frac{\bar d - \mu_0}{\frac{S_d}{\sqrt n}}$$

此时，t统计量服从自由度为 n-1 的t分布。因为我们的原假设是 $\mu_d = 0$，所以此处取 $\mu_0 = 0$。

然后我们选择显著性水平为5%，即 $\alpha = 0.05$，根据自由度和显著性水平，我们可以得到，原假设的拒绝域为
$$ \lvert t \rvert = \left| \frac{\bar d}{\frac{S_d}{\sqrt n}} \right| \gt t_{\frac{\alpha}{2}} (n-1) $$

我们查表或者通过t分布的累积概率密度函数计算得到 $t_{\frac{\alpha}{2}} (n-1)$ 的值，或者将不等式展开，转化为对 $\bar d$ 限定的形式：
$$ \lvert{\bar d}\rvert \gt \frac{S_d}{\sqrt n} \cdot t_{\frac{\alpha}{2}} (n-1)$$

然后我们可以判断是否拒绝原假设。此外，我们可以计算 $\mu_d$ 的置信区间。假设我们需要计算置信度为95%的置信区间，则 $\alpha = 0.05$，相应的置信区间为：
$$ \bar d \pm \frac{S_d}{\sqrt n} \cdot t_{\frac{\alpha}{2}} (n-1)$$

在实际应用的时候，往往还会需要pm提供一个差异的心里预期值，比如 1% 或 5% 等，通过检查两组数据差异的置信区间是否在预期值之上，可以进一步评估实验的效果。

## 结语
以上就是我这一段时间接触到的A/B测试中用到的主要统计学原理，主要是针对单个统计量的情况，而实际的实验中我们往往需要通过评估多个统计量的变化来对比两组样本的效果差异。如何根据多个统计指标设计评估模型，是我们面对的下一个问题。

## References
[A/B Testing](https://en.wikipedia.org/wiki/A/B_testing)

[抽样](https://zh.wikipedia.org/wiki/%E6%8A%BD%E6%A8%A3)

[正态分布](https://zh.wikipedia.org/wiki/%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83)

[t分布](https://zh.wikipedia.org/wiki/%E5%AD%A6%E7%94%9Ft-%E5%88%86%E5%B8%83)

[吆喝科技帮助手册](http://doc.appadhoc.com/dataDecision/interpret.html)

[什么是t值——Minitab](http://support.minitab.com/zh-cn/minitab/17/topic-library/basic-statistics-and-graphs/hypothesis-tests/tests-of-means/what-is-a-t-value/)

[Hypothesis Testing -- uncfsu](http://faculty.uncfsu.edu/dwallace/shyp.html)
